---
title: "ME315-day03"
output: html_document
---

# Demonstration

This question involves the use of multiple linear regression on the `Auto` data set from the ISLR package.

(a) Load the data, remove missing values and use the function `summary` to obtain univariate descriptive statistics.

```{r}
library(ISLR)
Auto = na.omit(Auto)
summary(Auto)
```

(b) Produce a scatterplot matrix which includes all of the variables in the data set.

```{r}
pairs(Auto)
```

(c) Compute the matrix of correlations between the variables using the function `cor()`. You will need to exclude the `name` variable, which is qualitative.

```{r}
cor(subset(Auto, select = -name))
```

(d) Use the `lm()` function to perform a multiple linear regression with `mpg` as the response and all other variables except `name` as the predictors. Use the `summary()` function to print the results. Comment on the output. For instance:

```{r}
lm.fit1 <-  lm(mpg ~ .-name, data=Auto)
summary(lm.fit1)
```

    i. Is there a relationship between the predictors and the response?

**Yes, there is a relatioship between the predictors and the response by testing the null hypothesis of whether all the regression coefficients are zero. The F -statistic is far from 1 (with a small p-value), indicating evidence against the null hypothesis.**

    ii. Which predictors appear to have a statistically significant relationship to the response?

**Looking at the p-values associated with each predictor's t-statistic, we see that displacement, weight, year, and origin have a statistically significant relationship, while cylinders, horsepower, and acceleration do not.**

    iii. What does the coefficient for the `year` variable suggest?

**The regression coefficient for year, ``r coefficients(lm.fit1)["year"]``, suggests that for every one year, mpg increases by the coefficient. In other words, cars become more fuel efficient every year by almost 1 mpg / year.**

(e) Use the `plot()` function to produce diagnostic plots of the linear regression fit. Comment on any problems you see with the fit.  

```{r}
plot(lm.fit1,which=c(1,2))
```
**Seems to be non-linear pattern, linear model not the best fit.**


(f) Use the `*` and `:` symbols to fit linear regression models with interaction effects. Do any interactions appear to be statistically significant?

```{r}
lm.fit2 <-  lm(mpg ~ cylinders * displacement + displacement * weight, data=Auto)
summary(lm.fit2)
```

**Interaction between displacement and weight is statistically signifcant, while the interactiion between cylinders and displacement is not.**

```{r}
lm.fit3 = lm(mpg ~ log(weight) + sqrt(horsepower) + acceleration+I(acceleration^2), data = Auto)
summary(lm.fit3)
plot(lm.fit3,which=c(1,2))
```

log(weight), sqrt(horsepower), and acceleration^2 all have statistical significance of some sort. The residuals plot has less of a discernible pattern than the plot of all linear regression terms. 

However, 2 problems are observed from the above plots: 1) the residuals vs fitted plot indicates heteroskedasticity (unconstant variance over mean) in the model. 2) The Q-Q plot indicates somewhat unnormality of the residuals.

So, a better transformation need to be applied to our model. From the correlation matrix in 9a., displacement, horsepower and weight show a similar nonlinear pattern against our response mpg. This nonlinear pattern is very close to a log form. So in the next attempt, we use log(mpg) as our response variable.

The outputs show that log transform of mpg yield better model fitting (better R^2, normality of residuals).

```{r}
lm.fit4<-lm(log(mpg)~cylinders+displacement+horsepower+weight+acceleration+year+origin,data=Auto)
summary(lm.fit4)
plot(lm.fit4,which=c(1,2))
```

# Activity

This question should be answered using the `Carseats` dataset from the `ISLR` package.

(a) Fit a multiple regression model to predict `Sales` using `Price`,
`Urban`, and `US`.

(b) Provide an interpretation of each coefficient in the model. Be
carefulâ€”some of the variables in the model are qualitative!

(c) Write out the model in equation form, being careful to handle the qualitative variables properly.

(d) For which of the predictors can you reject the null hypothesis $H_0 : \beta_j =0$?

(e) On the basis of your response to the previous question, fit a smaller model that only uses the predictors for which there is evidence of association with the outcome.

(f) How well do the models in (a) and (e) fit the data?

(g) Using the model from (e), obtain 95% confidence intervals for the coefficient(s).

### Reply here
